{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graphical Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### COMP4670/8600 - Statistical Machine Learning - Tutorial\n",
    "\n",
    "### Assumed knowledge\n",
    "- Undirected graphical models (lectures)\n",
    "\n",
    "### After this lab, you should be comfortable with:\n",
    "- Basic operations and definitions of graphical models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from IPython.display import display, Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the second part of the tutorial, we will talk about Markov random fields (MRFs)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Markov Random Fields\n",
    "\n",
    "Markov random fields (MRFs) are similar to Bayesian networks (BNs), but with undirected edges. This means that the causal relationships in BNs are no longer defined in MRFs. The relationship between nodes connected by an edge is only \"correlational\" now.\n",
    "\n",
    "Consider an undirected grapical model. Let $C$ denote a *clique* of the graph, corresponding to the set of variables $\\mathsf{x}_C$. We assign a *potential function* $\\psi_C(\\mathsf{x}_C) \\geq 0$ to each set. The joint distribution of all variables in that graph is \n",
    "$$\n",
    "p(\\mathsf{x}) = \\frac{1}{Z} \\prod_{C} \\psi_C(\\mathsf{x}_C),\n",
    "$$\n",
    "where $Z = \\sum_{x}\\prod_{C} \\psi_C(\\mathsf{x}_C)$ is the *normalising constant* to ensure $p(\\mathsf{x})$ sums to 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting a Bayesian net to an MRF\n",
    "\n",
    "To convert a BN into an MRF, we perform the following steps:\n",
    "1. \"Marry\" the parents: add additional undirected edges between all pairs of parents for each node in the graph. This step is also called \"moralisation\".\n",
    "2. Drop the arrows on all original edges. You should now have an fully undirected graph often called a *moral graph*.\n",
    "3. For each clique in the undirected graph, intialise its potential to 1.\n",
    "4. For each conditional probability in the original graph, multiply it into a corresponding clique potential.\n",
    "5. The normalising constant is simply $Z = 1$.\n",
    "\n",
    "Note that the resulting MRF may represent different conditional independence statements than the original BN.\n",
    "\n",
    "Let's work on one example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1.** Revisit the Bayesian network we worked on last week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(url=\"https://machlearn.gitlab.io/sml2021/tutorials/graphical_model.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert this graph into a moral graph. This corresonds to Steps 1 and 2 above. Draw the resulting network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace this with your solution, add and remove code and markdown cells as appropriate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2.** Answer the following:\n",
    "\n",
    "(a) Identify the maximal cliques in the graph and write down the corresponding clique potentials. This corresponds to Steps 3 and 4 above.\n",
    "\n",
    "(b) Then write out the joint distribution of the undirected graph. \n",
    "\n",
    "(c) Compare the conditional independence statements of the MRF with the BN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\">Answer</span>\n",
    "<i>--- replace this with your solution, add and remove code and markdown cells as appropriate ---</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sum-Product Algorithm\n",
    "\n",
    "The aim of this exercise is to implement the sum product algorithm on a chain graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Factor graphs\n",
    "\n",
    "Revise the definition of a factor graph in part 3 of the lectures (or Section 8.4.3 of the textbook). A nice property about factor graphs is that the joint distribution can can be expressed as a product of factors. This is important later when we revisit the sum-product algorithm.\n",
    "\n",
    "Here we remind you of how to convert a graph (directed or undirected) into a factor graph.\n",
    "\n",
    "To convert a directed graph into a factor graph:\n",
    "1. Add a factor node corresponding to each conditional probability.\n",
    "2. Assign a conditional probability to the value of its corresponding factor.\n",
    "3. Connect a factor to its corresponding nodes in the conditional probability. \n",
    "\n",
    "To convert an undirected graph into a factor graph:\n",
    "1. Add a factor node corresponding to each maximal clique.\n",
    "2. Create a factor for $Z$, which is over an empty set of variables.\n",
    "3. Assign a clique potential to the value of its corresponding factor.\n",
    "4. Connect a factor to its corersponding nodes in the original clique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributive law\n",
    "\n",
    "The [distributive property](http://en.wikipedia.org/wiki/Distributive_property) can be used to save computation, and is the basis of message passing and dynamic programming. See an [anecdote](http://bibiserv.techfak.uni-bielefeld.de/dynprog/node3_mn.html) about camels.\n",
    "\n",
    "**Exercise 3.** Consider the following equation:\n",
    "$$\n",
    "2*3 + 2*5 = 2 * (3+5).\n",
    "$$\n",
    "\n",
    "* How many mathematical operations (multiplications and additions) are on the left hand side?\n",
    "* How many mathematical operations are on the right hand side?\n",
    "\n",
    "Construct a larger example where there is even more computational savings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\">Answer</span>\n",
    "<i>--- replace this with your solution, add and remove code and markdown cells as appropriate ---</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Message passing\n",
    "\n",
    "Consider the following factor graph. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(url=\"https://machlearn.gitlab.io/sml2021/tutorials/message_passing.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The factors are given by the following tables:\n",
    "\n",
    "|f(A,B)  | A=$\\square$ | A=$\\bigcirc$ | A = $\\clubsuit$ | A = $\\heartsuit$ | A = $\\triangle$ |\n",
    "|--|:--:|:--:|:--:|:--:|:--:|\n",
    "|**B**=$p$|0.01|0.01|0.12|0.01|0.14|\n",
    "|**B**=$q$|0.03|0.15|0.01|0.01|0.01|\n",
    "|**B**=$r$|0.13|0.11|0.07|0.18|0.01|\n",
    "\n",
    "|g(B,C) | B=$p$ | B=$q$ | B=$r$ |\n",
    "|--|:--:|:--:|:--:|\n",
    "|**C**=$w$|0.05|0.06|0.07|\n",
    "|**C**=$x$|0.1|0.3|0.2|\n",
    "|**C**=$y$|0.03|0.02|0.1|\n",
    "|**C**=$z$|0.11|0.15|0.08|\n",
    "\n",
    "|  | h(C) |\n",
    "|--|:--:|\n",
    "|**C**=$w$|1.2|\n",
    "|**C**=$x$|3.2|\n",
    "|**C**=$y$|1.8|\n",
    "|**C**=$z$|2.3|\n",
    "\n",
    "Using the sum product algorithm, compute the marginal distribution of the random variable $B$.\n",
    "\n",
    "*Hint: Note that the factors are not normalised.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\">Answer</span>\n",
    "<i>--- replace this with your solution, add and remove code and markdown cells as appropriate ---</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Textbook Questions\n",
    "\n",
    "- Q8.20: Induction on graph structure (recall from MATH1005/6005) (Difficulty $\\star$)\n",
    "- Q8.21: Note typo: it should be $f_s(x_s)$ (Difficulty $\\star\\star$)\n",
    "- Q8.27: Construct example showing greedy method not working (Difficulty $\\star\\star$)\n",
    "- Q8.29: Induction on tree structure (recall from MATH1005/6005) (Difficulty $\\star\\star$)\n",
    "- Extra: Derive eq 8.74 to 8.85 w.r.t Fig 8.51\n",
    "\n",
    "- Q10.2: Solving simulataneous equations (Difficulty $\\star$)\n",
    "- Q10.3: Use lagrangian to enforce normalisation of q (Difficulty $\\star\\star$)\n",
    "- Q10.6: Hint, how to introduce log term for both p and q? (Difficulty $\\star\\star$)\n",
    "\n",
    "- Q2.44: Manipulation with a more complex conjugate to derive the posterior (Difficulty $\\star\\star$)\n",
    "\n",
    "- Q10.7: Rewritting to the form of the respective distributions. Mostly algebra. (Difficulty $\\star\\star$)\n",
    "- Q10.8: What will $b_n$ be approximated as? (Difficulty $\\star$)\n",
    "- Q10.9: Essentially, deriving 10.31 and 10.32 (Difficulty $\\star\\star$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
